# Introduction 
This repository contains scripts for populating the Neo4j MDR Database
with the dictionaries and sponsor data that StudyBuilder requires.

It also contains some sample study data.

# Python Getting Started

This section is written for running on Ubuntu (that uses the `apt` package manager).
Other systems can also be used, but the commands for installing packages will be different.

This project uses https://github.com/pypa/pipenv for dependencies management,
so you must install it on your system.
Version 2020.8.13 or later is needed.
Ubuntu 20.04 ships and old version, so use `pip` instead of `apt` to install pipenv.

```
$ python3 --version
$ pip --version
$ pip install pipenv
```
**Note:** In case your system has a newer version of python than 3.7 (e.g. 3.8 as of Ubuntu 20.04),
you can install version 3.7 (leaving system default intact) with:
```
$ sudo add-apt-repository ppa:deadsnakes/ppa
$ sudo apt-get update
$ sudo apt-get install python 3.7
```


# Running
## Preparations
This

These migration scripts populate the database via the api (`clinical-mdr-api`).
Thus they require both the Neo4j database and the clinical-mdr-api to be running.
They also require the clinical standards data to be available in the database.

See the READMEs in the `neo4j-mdr-db`, `mdr-standards-import` and `clinical-mdr-api`
repositories on how to start and initialize the database, import standards, and start the api.

Once the preparations are done, continue with setting up an environment file, `.env`.

## Setup environment variables
Create `.env` file (in the root of cloned repository). Use the `.env.import` file as a template and adjust as needed.

The most important variable to configure is the url of the api:
```
API_BASE_URL="http://localhost:8000"
```
Adjust this if the api is not running on localhost at port 8000.

There are two more general variables:
```
LOG_LEVEL=INFO
MDR_MIGRATION_SAMPLE=False
```
`LOG_LEVEL` determines the logging level. `INFO` is the recommended setting for normal use.
This shows info level messages, and hides `DEBUG` and `TRACE`.

`MDR_MIGRATION_SAMPLE` determines if a small subset of data should be imported
rather than the full content of the provided files.
This should normally be set to `False` to ensure a complete set of data is imported.
Only enable this to save time while doing work on the import scripts themselves.

The rest of the .env-file contains various settings for customizing the behavior of the import script.
It also determines which files are used by each import step.
The `.env.import` example is set up to import everything except the dummy development study,
using the files from the `datatfiles` directory. 

## Activate pipenv

Activate pipenv by running:

```
$ pipenv install
```

## Run full import
Run the following command to start the full import.

```sh
$ pipenv run import_all
```
**Note:** This will take some time to run.

## Partial import

It is also possible to run only a single part of the import with ```pipenv run {scriptname}```. The available commands are listed under `[scripts]` in the `Pipfile`.

The current set of commands is:
- import_all (runs all of the others in the order listed here)
- dictionaries
- config
- codelistterms1
- codelistterms2
- unitdefinitions
- activities
- codelistfinish
- compounds
- crfs
- mockdata
- mockdatajson


# Import steps
This lists the various steps that the import goes through,
as well as what environment variables that determine which files are used.

## Steps
### Dictionaries: `dictionaries`
| step | environment variable(s) |
|------|-------------------------|
| dictionary definitions | MDR_MIGRATION_DICTIONARIES_CODELISTS_DEFINITIONS |
| snomed | MDR_MIGRATION_SNOMED |
| med rt | MDR_MIGRATION_MED_RT |
| unii | MDR_MIGRATION_UNII |
| ucum | MDR_MIGRATION_UCUM |


### Study fields configuration: `config`
| step | environment variable(s) |
|------|-------------------------|
| study field config | MDR_STUDY_FIELDS_DEFINITIONS |

### Additions to codelists
| step | environment variable(s) |
|------|-------------------------|
| Additional terms for the frequency codelist, C71113 | MDR_MIGRATION_FREQUENCY |

### Sponsor library content, standard codelists
| step | environment variable(s) |
|------|-------------------------|
| sponsor codelist definitions. Used to create the lists, no content here. | MDR_MIGRATION_SPONSOR_CODELIST_DEFINITIONS |
| operator (equal, larger than, etc) | MDR_MIGRATION_OPERATOR |
| epoch (collect terms from cdisc in sponsor codelist, add a few terms not in cdisc) | MDR_MIGRATION_EPOCH <br> MDR_MIGRATION_EPOCH_TYPE <br> MDR_MIGRATION_EPOCH_SUB_TYPE |
| endpoint | MDR_MIGRATION_ENDPOINT_LEVEL |
| endpoint (sub) category | MDR_MIGRATION_ENDPOINT_CATEGORY <br> MDR_MIGRATION_ENDPOINT_SUB_CATEGORY |
| activities | MDR_MIGRATION_ACTIVITIES <br> MDR_MIGRATION_ACTIVITY_SUB_GROUPS <br> MDR_MIGRATION_ACTIVITY_GROUPS <br> MDR_MIGRATION_ACTIVITY_INSTANCES |
| objective | MDR_MIGRATION_OBJECTIVE_LEVEL |
| codelist parameter set, used to mark codelist terms as template parameters | MDR_MIGRATION_CODELIST_PARAMETER_SET |
| arm type | MDR_MIGRATION_ARM_TYPE |
| criteria type | MDR_MIGRATION_CRITERIA_CATEGORY <br> MDR_MIGRATION_CRITERIA_SUB_CATEGORY <br> MDR_MIGRATION_CRITERIA_TYPE |
| compound dispensed in | MDR_MIGRATION_COMPOUND_DISPENSED_IN |
| device | MDR_MIGRATION_DEVICE |
| dosage form, define sponsor preferred names for cdisc terms | MDR_MIGRATION_DOSAGE_FORM |
| element (sub)type | MDR_MIGRATION_ELEMENT_TYPE <br> MDR_MIGRATION_ELEMENT_SUBTYPE |
| flowchart group | MDR_MIGRATION_FLOWCHART_GROUP |
| objective category | MDR_MIGRATION_OBJECTIVE_CATEGORY |
| therapy area | MDR_MIGRATION_THERAPY_AREA |
| time reference | MDR_MIGRATION_TIME_REFERENCE |
| type of treatment | MDR_MIGRATION_TYPE_OF_TREATMENT |
| sponsor defined units (extending SDTM) | MDR_MIGRATION_SPONSOR_UNITS |
| unit definitions | MDR_MIGRATION_UNIT_DIF |
| unit dimension | MDR_MIGRATION_UNIT_DIMENSION |
| unit subset | MDR_MIGRATION_UNIT_SUBSETS |
| visit contact mode | MDR_MIGRATION_VISIT_CONTACT_MODE |
| visit type | MDR_MIGRATION_VISIT_TYPE |
| visit sub label | MDR_MIGRATION_VISIT_SUB_LABEL |
| null flavor | MDR_MIGRATION_NULL_FLAVOR |

### CRFs
| step | environment variable(s) |
|------|-------------------------|
| crf templates | MDR_MIGRATION_ODM_TEMPLATES |
| forms | MDR_MIGRATION_ODM_FORMS |
| groups | MDR_MIGRATION_ODM_ITEMGROUPS |
| items | MDR_MIGRATION_ODM_ITEMS |

### Sponsor terms
| step | environment variable(s) |
|------|-------------------------|
| compounds | MDR_MIGRATION_COMPOUNDS |

### Mock data: `mockdata`
Set up some mock data to have something to show.

| step | environment variable(s) |
|------|-------------------------|
| studies | MDR_MIGRATION_STUDY <br> MDR_MIGRATION_STUDY_TYPE |
| projects | MDR_MIGRATION_PROJECTS |
| objectives | MDR_MOCKUP_OBJECTIVES_OBJECTS |
| endpoints | MDR_MOCKUP_ENDPOINTS_OBJECTS |
| timeframes | MDR_MOCKUP_TIMEFRAMES_OBJECTS |
| study objectives | MDR_MOCKUP_STUDY_OBJECTIVES |
| study endpoints | MDR_MOCKUP_STUDY_ENDPOINTS |

### Exported data from json: `mockdatajson`
(TODO rename the script! It's not only used for mockup data)
This step imports data that is exported by the [studybuilder-export](https://dev.azure.com/novonordiskit/Clinical-MDR/_git/studybuilder-export) script.
What files to use is configured by a single variable that points to the exported project listing.
Other files are found via their names that match their corresponding api endpoints. 

```
IMPORT_PROJECTS="datafiles/mockup/exported/projects.json"
```

#### Selective import

There are a number of options for limiting what is imported from json. 
The different parts can be skipped by setting the corresponding variable to `False`.
When importing studies, there are two variables for selecting which studies are imported. 
- `INCLUDE_STUDY_NUMBERS`:  list of study numbers that should be included
- `EXCLUDE_STUDY_NUMBERS`:  study numbers to exclude

The logic is that it first filters the available studies to include 
only the ones in `INCLUDE_STUDY_NUMBERS`.
If `INCLUDE_STUDY_NUMBERS` is not specified, then all are included.

After this it then removes any study listed in `EXCLUDE_STUDY_NUMBERS`.

Both accept a comma-separated list of study numbers, like `1001,1002,1234`.

The standard datafiles includes a dummy study intended to help starting up
development environments.
This is enabled by setting `MDR_MIGRATION_INCLUDE_DUMMY_STUDY=True`.

This creates a study with number 9999 that has some dummy data in most parts.

Setting `MDR_MIGRATION_RENUMBER_DUMMY_STUDY=True` will import the dummy study
as a new study number instead of updating the existing one.
It then starts from 9999 and decrements the number until it finds one that is free.

It's possible to skip parts of the json import.
This is controlled via a set of environment variables that take `True` to enable the import, and `False` for disabling.

| part | variable |
|------|----------|
| clinical programmes | MDR_MIGRATION_EXPORTED_PROGRAMMES |
| brands | MDR_MIGRATION_EXPORTED_BRANDS |
| activities | MDR_MIGRATION_EXPORTED_ACTIVITIES |
| unit definitions | MDR_MIGRATION_EXPORTED_UNITS |
| compounds | MDR_MIGRATION_EXPORTED_COMPOUNDS |
| syntax templates | MDR_MIGRATION_EXPORTED_TEMPLATES |
| projects | MDR_MIGRATION_EXPORTED_PROJECTS |
| studies | MDR_MIGRATION_EXPORTED_STUDIES |

Example that includes everything:
```
MDR_MIGRATION_EXPORTED_PROGRAMMES=True
MDR_MIGRATION_EXPORTED_BRANDS=True
MDR_MIGRATION_EXPORTED_ACTIVITIES=True
MDR_MIGRATION_EXPORTED_UNITS=True
MDR_MIGRATION_EXPORTED_COMPOUNDS=True
MDR_MIGRATION_EXPORTED_TEMPLATES=True
MDR_MIGRATION_EXPORTED_PROJECTS=True
MDR_MIGRATION_EXPORTED_STUDIES=True
INCLUDE_STUDY_NUMBERS=""
EXCLUDE_STUDY_NUMBERS=""
MDR_MIGRATION_INCLUDE_DUMMY_STUDY=True
MDR_MIGRATION_RENUMBER_DUMMY_STUDY=True
```

#  Authentication

Supports [OAuth 2.0 client credentials flow with shared secret](https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow#first-case-access-token-request-with-a-shared-secret).
Credentials can be configured by setting all the following environment variables.
If *CLIENT_ID* is set, the authentication routine is activated.

```shell
CLIENT_ID="aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee"
CLIENT_SECRET="...FILL-ME..."
TOKEN_ENDPOINT="https://login.microsoftonline.com/aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee/oauth2/v2.0/token"
SCOPE="api://aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee/.default"
```

- **TOKEN_ENDPOINT** is the endpoint where to post the authentication request.
  Can be found in the OpenID Connect metadata document, or Azure Active Directory -> App registrations -> Endpoints.
- **SCOPE** is the scope to request at the authentication flow, and in case of the Microsoft Identity Platform,
  that is the application ID (in URI format) of the API and *.default*
  The main point here is that the OAuth authority should give back a valid access token.
- **CLIENT_ID** is the application id registered for this client application
- **CLIENT_SECRET** is one of the secret key values set up with the client application at the authority

Authentication is done once per migration script session, fetching an access token which is then included in each
request as the *Authorization* header.

# Sample data and scripts

There is a selection of sample Cypher scripts that are useful for testing
and learning more about Cypher and the datamodel. See the `sample_scripts` folder.
These scripts rely on some files in the `datafiles/libraries/concepts/crfs` and `migration_test_data\unused` folders.

# Adding sponsor terms and codelists

## Add a term to an existing list

To add a new term to a sponsor codelist, simply edit the corresponding .csv file.

Let's add a new to the "Compound dispensed in" codelist (with codelist submission value "COMP_DISP_IN").

The file is stored at `./datafiles/sponsor_library/compound_dispensed_in.csv`


| "CT_CD_LIST_SUBMVAL" | "CT_NAME" | "NAME_SENTENSE_CASE" | "CT_SUBMVAL" |"DEFINITION" | "ORDER" |
| -------------------- | --------- | -------------------- | ------------ | ----------- | ------- |
| "COMP_DISP_IN" | "Cartridge" | "cartridge" | "DISPENSED IN CARTRIDGE" | "Cartridge" | "103" |
| "COMP_DISP_IN" | "Pre-filled pen" | "pre-filled pen" | "DISPENSED IN PREFILLED PEN" | "Pre-filled pen" | "116" |
| "COMP_DISP_IN" | "Blister" | "blister" | "DISPENSED IN BLISTER" | "Blister" | "102" |
| "COMP_DISP_IN" | "Vial" | "vial" | "DISPENSED IN VIAL" | "Vial" | "122" |

Since all terms in this list belong to the same codelist, they all have the codelist  

Let's add the term "Ampoule", with submssion value (`CT_SUBMVAL`) "DISPENSED IN AMPOULE".

We want it listed just above "Vial" in the UI, so we set order to 121. 

For definition we use "Small sealed glass or plastic vial"

`CT_NAME` is the term name, while `NAME_SENTENCE_CASE` is a variation of the name that is used in running text.

The line to add at the end of the file is thus:
```
"COMP_DISP_IN","Ampoule","ampoule","DISPENSED IN AMPOULE","Small sealed glass or plastic vial","121"
```

After this, run just the `codelistterms2` Pipenv command:
```sh
$ pipenv run codelistterms2
```

## Add a new codelist

Adding a new codelist consists of a few more steps than adding a single term.
This example will add the dummy codelist "Icecream Flavor", with the terms "Chocolate" and "Vanilla".

### Add the codelist definition

The sponsor codelists are defined in the file `datafiles/sponsor_library/sponsor_codelist_definitions.csv`.

We need to add a line at the end to define the new codelist:

| library | catalogue | legacy_codelist_id | legacy_codelist_name | new_codelist_name | template_parameter | submission_value | preferred_term | definition | extensible | synonyms | href |
| ------- | --------- | ------------------ | -------------------- | ----------------- | ------------------ | ---------------- | -------------- | ---------- | ---------- | -------- | ---- |
| Sponsor | SDTM CT | ICECREAM_FLAVOR | Icecream Flavor | Icecream Flavor | Y | ICECREAM_FLAVOR | Icecream Flavor | "Selection of icecream flavors" | Y | | |

Description of fields
- library: Set to "Sponsor" since this is a sponsor-defined codelist.
- catalogue: The catalogue that this should belong to. SDTM CT is used as an example.
- legacy_codelist_id: If the codelist is migrated from a legacy system, this is the id of the list in that system. Not currently used by the import script.
- legacy_codelist_name: Same as legacy_codelist_id but for name instead of id.
- new_codelist_name: The name of the codelist in StudyBuilder.
- template_parameter: "Y" if the codelist terms should be available as template parameters for use in syntax templates, else "N".
- submission_value: Codelist submission value.
- preferred_term: The name that is displayed.
- definition: The definition, describing the list.
- extensible: "Y" or "N" if the list should be user extensible.
- synonyms: Synonyms for the codelist. Not currently used by the import script.
- href: Not currently used by the import script.


### Add the codelist terms
Create the new codelist .csv file with the following content:

| "CT_CD_LIST_SUBMVAL" | "CT_NAME" | "NAME_SENTENSE_CASE" | "CT_SUBMVAL" |"DEFINITION" | "ORDER" | "CT_CD" |
| -------------------- | --------- | -------------------- | ------------ | ----------- | ------- | ------- |
| "ICECREAM_FLAVOR" | "Vanilla" | "vanilla" | "VANILLA FLAVOR" | "Plain vanilla flavor" | "1" |     |
| "ICECREAM_FLAVOR" | "Chocolate" | "chocolate" | "CHOCOLATE FLAVOR" | "Flavored with pieces of chocolate" | "2" | "C99999" |

Description of fields
- CT_CD_LIST_SUBMVAL: Reference to the Codelist
- CT_NAME: Name of the Term
- NAME_SENTENSE_CASE: Name of the Term but in lower case
- CT_SUBMVAL: Submission value of the Term (should be in capital)
- DEFINITION: Definition of the Term
- ORDER: Order of the Term in the dedicated Codelist
- CT_CD: Leave empty if it is a newly Term, otherwise, provide the ConceptID of the existing CDISC Term (with Cxxxxxx)

Save this as `./datafiles/sponsor_library/icecream_flavor.csv`

### Add an import step for the new list
Edit the `.env` file to add a new variable for the new file:
(Please add this also to the .env.import and to the .env.e2e for reference)
```
MDR_MIGRATION_ICECREAM_FLAVOR="datafiles/sponsor_library/icecream_flavor.csv"
```

Please remember here to 'duplicate' those evolution inside the folder e2e_datafiles (Otherwise you will get an error in the pipeline)

Edit the script `run_import_standardcodelistterms2.py`.

Find the block of lines near the top where it reads the environment variables,
and add this line at the end likely near line 60:
```
 60| MDR_MIGRATION_ICECREAM_FLAVOR = load_env("MDR_MIGRATION_ICECREAM_FLAVOR")
```

Locate the function `async_run()`, that should be around line 147:
```
147|    async def async_run(self):
```

At the end of this function, add a new call to `migrate_term()`, again with approximate line numbers:
```
342|            await self.migrate_term(
343|                MDR_MIGRATION_ICECREAM_FLAVOR,
344|                codelist_name="Icecream Flavor",
345|                code_lists_uids=code_lists_uids,
346|                session=session,
347|            )
```

### Run the import to add the new list and its terms

Start by running the `codelistterms1` Pipenv command:

```sh

$ pipenv run codelistterms1

```

This creates all sponsor codelists, as well as imports the first set of sponsor codelist terms.

After this, run the `codelistterms2` Pipenv command:
```sh
$ pipenv run codelistterms2
```
This imports all sponsor codelists.
This command also imports more than needed, but also finishes rather quickly
and won't cause any troubles with the codelists that were already imported since before.
